---
title: kafka_server
slug: kafka_server
type: input
status: beta
categories: ["Services"]
---

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the corresponding source file under internal/impl/<provider>.
-->

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

:::caution BETA
This component is mostly stable but breaking changes could still be made outside of major version releases if a fundamental problem with the component is found.
:::
Runs a Kafka-protocol-compatible server that accepts produce requests from Kafka producers.

Introduced in version 1.15.0.


<Tabs defaultValue="common" values={[
  { label: 'Common', value: 'common', },
  { label: 'Advanced', value: 'advanced', },
]}>

<TabItem value="common">

```yml
# Common config fields, showing default values
input:
  label: ""
  kafka_server:
    address: 0.0.0.0:9092
```

</TabItem>
<TabItem value="advanced">

```yml
# All config fields, showing default values
input:
  label: ""
  kafka_server:
    address: 0.0.0.0:9092
    advertised_address: ""
    topics: []
    tls:
      enabled: false
      skip_cert_verify: false
      enable_renegotiation: false
      root_cas: ""
      root_cas_file: ""
      client_certs: []
    sasl: [] # No default (optional)
    timeout: 5s
    idle_timeout: "0"
    max_message_bytes: 1048576
    idempotent_write: false
```

</TabItem>
</Tabs>

This input acts as a Kafka broker endpoint, allowing Kafka producers to send messages directly into a Bento pipeline without requiring a full Kafka cluster.

Similar to the `http_server` input, this creates a server that external clients can push data to. The difference is that clients use the Kafka protocol instead of HTTP.

### Metadata

This input adds the following metadata fields to each message:

```text
- kafka_server_topic
- kafka_server_partition
- kafka_server_key
- kafka_server_timestamp
- kafka_server_timestamp_unix
- kafka_server_client_address
```

Message headers from Kafka records are also added as metadata fields.

You can access these metadata fields using [function interpolation](/docs/configuration/interpolation#bloblang-queries).

## Examples

<Tabs defaultValue="Basic Usage" values={[
{ label: 'Basic Usage', value: 'Basic Usage', },
{ label: 'With TLS', value: 'With TLS', },
{ label: 'With SASL PLAIN Authentication', value: 'With SASL PLAIN Authentication', },
{ label: 'With SASL SCRAM Authentication', value: 'With SASL SCRAM Authentication', },
]}>

<TabItem value="Basic Usage">

Accept Kafka produce requests and write to stdout

```yaml
input:
  kafka_server:
    address: "0.0.0.0:9092"
    topics:
      - events
      - logs

output:
  stdout: {}
```

</TabItem>
<TabItem value="With TLS">

Accept Kafka produce requests over TLS

```yaml
input:
  kafka_server:
    address: "0.0.0.0:9093"
    tls:
      enabled: true
      client_certs:
        - cert_file: /path/to/cert.pem
          key_file: /path/to/key.pem
```

</TabItem>
<TabItem value="With SASL PLAIN Authentication">

Accept authenticated Kafka produce requests using PLAIN

```yaml
input:
  kafka_server:
    address: "0.0.0.0:9092"
    tls:
      enabled: true
      client_certs:
        - cert_file: /path/to/cert.pem
          key_file: /path/to/key.pem
    sasl:
      - mechanism: PLAIN
        username: producer1
        password: secret123
      - mechanism: PLAIN
        username: producer2
        password: secret456
```

</TabItem>
<TabItem value="With SASL SCRAM Authentication">

Accept authenticated Kafka produce requests using SCRAM-SHA-256

```yaml
input:
  kafka_server:
    address: "0.0.0.0:9092"
    tls:
      enabled: true
      client_certs:
        - cert_file: /path/to/cert.pem
          key_file: /path/to/key.pem
    sasl:
      - mechanism: SCRAM-SHA-256
        username: producer1
        password: secret123
      - mechanism: SCRAM-SHA-512
        username: producer2
        password: secret456
```

</TabItem>
</Tabs>

## Fields

### `address`

The address to listen on for Kafka protocol connections.


Type: `string`  
Default: `"0.0.0.0:9092"`  

### `advertised_address`

The address to advertise to clients in metadata responses. If empty, the listen address is used. This is useful when the server is behind a NAT or load balancer, or when clients connect through a different network interface (e.g., Docker containers connecting via host.docker.internal).


Type: `string`  
Default: `""`  

### `topics`

Optional list of topic names to accept. If empty, all topics are accepted.


Type: `array`  
Default: `[]`  

### `tls`

Custom TLS settings can be used to override system defaults.


Type: `object`  

### `tls.enabled`

Whether custom TLS settings are enabled.


Type: `bool`  
Default: `false`  

### `tls.skip_cert_verify`

Whether to skip server side certificate verification.


Type: `bool`  
Default: `false`  

### `tls.enable_renegotiation`

Whether to allow the remote server to repeatedly request renegotiation. Enable this option if you're seeing the error message `local error: tls: no renegotiation`.


Type: `bool`  
Default: `false`  
Requires version 1.0.0 or newer  

### `tls.root_cas`

An optional root certificate authority to use. This is a string, representing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.
:::warning Secret
This field contains sensitive information that usually shouldn't be added to a config directly, read our [secrets page for more info](/docs/configuration/secrets).
:::


Type: `string`  
Default: `""`  

```yml
# Examples

root_cas: |-
  -----BEGIN CERTIFICATE-----
  ...
  -----END CERTIFICATE-----
```

### `tls.root_cas_file`

An optional path of a root certificate authority file to use. This is a file, often with a .pem extension, containing a certificate chain from the parent trusted root certificate, to possible intermediate signing certificates, to the host certificate.


Type: `string`  
Default: `""`  

```yml
# Examples

root_cas_file: ./root_cas.pem
```

### `tls.client_certs`

A list of client certificates to use. For each certificate either the fields `cert` and `key`, or `cert_file` and `key_file` should be specified, but not both.


Type: `array`  
Default: `[]`  

```yml
# Examples

client_certs:
  - cert: foo
    key: bar

client_certs:
  - cert_file: ./example.pem
    key_file: ./example.key
```

### `tls.client_certs[].cert`

A plain text certificate to use.


Type: `string`  
Default: `""`  

### `tls.client_certs[].key`

A plain text certificate key to use.
:::warning Secret
This field contains sensitive information that usually shouldn't be added to a config directly, read our [secrets page for more info](/docs/configuration/secrets).
:::


Type: `string`  
Default: `""`  

### `tls.client_certs[].cert_file`

The path of a certificate to use.


Type: `string`  
Default: `""`  

### `tls.client_certs[].key_file`

The path of a certificate key to use.


Type: `string`  
Default: `""`  

### `tls.client_certs[].password`

A plain text password for when the private key is password encrypted in PKCS#1 or PKCS#8 format. The obsolete `pbeWithMD5AndDES-CBC` algorithm is not supported for the PKCS#8 format. Warning: Since it does not authenticate the ciphertext, it is vulnerable to padding oracle attacks that can let an attacker recover the plaintext.
:::warning Secret
This field contains sensitive information that usually shouldn't be added to a config directly, read our [secrets page for more info](/docs/configuration/secrets).
:::


Type: `string`  
Default: `""`  

```yml
# Examples

password: foo

password: ${KEY_PASSWORD}
```

### `sasl`

Configure one or more SASL credentials that clients can use to authenticate. When SASL is configured, clients must authenticate before sending produce requests. Multiple credentials can be configured for the same or different mechanisms.


Type: `array`  

```yml
# Examples

sasl:
  - mechanism: PLAIN
    password: password1
    username: user1
  - mechanism: SCRAM-SHA-256
    password: password2
    username: user2
```

### `sasl[].mechanism`

The SASL mechanism to use for this credential.


Type: `string`  

| Option | Summary |
|---|---|
| `PLAIN` | Plain text authentication. Credentials are sent in clear text, so TLS is recommended. |
| `SCRAM-SHA-256` | SCRAM based authentication as specified in RFC5802. |
| `SCRAM-SHA-512` | SCRAM based authentication as specified in RFC5802. |


### `sasl[].username`

The username for authentication.


Type: `string`  

### `sasl[].password`

The password for authentication.
:::warning Secret
This field contains sensitive information that usually shouldn't be added to a config directly, read our [secrets page for more info](/docs/configuration/secrets).
:::


Type: `string`  

### `timeout`

The maximum time to wait for a produce request to be processed by the pipeline and acknowledged. This timeout also applies to write operations when sending responses back to clients. If processing takes longer than this duration, the producer receives a timeout error, but the message may still be delivered to the pipeline.


Type: `string`  
Default: `"5s"`  

### `idle_timeout`

The maximum time a connection can be idle (no data received) before being closed. Use a larger value for producers that send infrequently. Set to 0 to disable idle timeout.


Type: `string`  
Default: `"0"`  

### `max_message_bytes`

The maximum size in bytes of a message payload.


Type: `int`  
Default: `1048576`  

### `idempotent_write`

Enable support for idempotent Kafka producers. When enabled, the server will respond to InitProducerID requests and allocate producer IDs. Note: This enables clients to use idempotent producers but does NOT provide actual exactly-once semantics - it only satisfies the protocol requirements.


Type: `bool`  
Default: `false`  


